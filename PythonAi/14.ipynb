{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTrainData():\n",
    "    cancer = load_breast_cancer()  # 加载乳腺癌数据\n",
    "    X = cancer.data  # 加载乳腺癌判别特征\n",
    "    y = cancer.target  # 两个TAG，y = 0时为阴性，y = 1时为阳性\n",
    "    # 将数据集划分为训练集和测试集，测试集占比为0.2\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    X_train = X_train.T\n",
    "    X_test = X_test.T\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(inx):\n",
    "    from numpy import exp\n",
    "    return 1.0/(1.0 + exp(-inx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化参数\n",
    "def initialize_para(dim):\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    np.random.seed(0)\n",
    "    w = np.random.normal(mu, sigma, dim)\n",
    "    w = np.reshape(w, (dim, 1))\n",
    "    b = 0\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前向传播\n",
    "def propagate(w, b, X, Y):\n",
    "    # eps防止log运算遇到0\n",
    "    eps = 1e-5\n",
    "    m = X.shape[1]\n",
    "    # 计算初步运算结果\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    # 计算损失函数值大小\n",
    "    cost = -1 / m * np.sum(np.multiply(Y, np.log(A + eps)) +\n",
    "                           np.multiply(1 - Y, np.log(1 - A + eps)))\n",
    "    # 计算梯度值\n",
    "    dw = 1 / m * np.dot(X, (A - Y).T)\n",
    "    db = 1 / m * np.sum(A-Y)\n",
    "    cost = np.squeeze(cost)\n",
    "\n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    # 返回损失函数大小以及反向传播的梯度值\n",
    "    return grads, cost, A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_iterations 梯度下降次数\n",
    "# learning_rate 学习率\n",
    "def optimize(w, b, X, Y, num_iterations, learning_rate):\n",
    "    costs = []  # 记录损失函数值\n",
    "\n",
    "    # 循环进行梯度下降\n",
    "    for i in range(num_iterations):\n",
    "        # print(i)\n",
    "        grads, cost, pre_Y = propagate(w, b, X, Y)\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "\n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "\n",
    "        # 每100次循环记录一次损失函数大小并打印\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            pre_Y[pre_Y >= 0.5] = 1\n",
    "            pre_Y[pre_Y < 0.5] = 0\n",
    "            pre_Y = pre_Y.astype(np.int)\n",
    "            acc = 1 - np.sum(pre_Y ^ Y) / len(Y)\n",
    "            print(\"Iteration:{} Loss = {}, Acc = {}\".format(i, cost, acc))\n",
    "\n",
    "    # 最终参数值\n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "\n",
    "    return params, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, X):\n",
    "    # 样本个数\n",
    "    m = X.shape[1]\n",
    "    # 初始化预测输出\n",
    "    Y_prediction = np.zeros((1, m))\n",
    "    # 转置参数向量w\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "\n",
    "    # 预测结果\n",
    "    Y_hat = sigmoid(np.dot(w.T, X) + b)\n",
    "\n",
    "    # 将结果按照0.5的阈值转化为0/1\n",
    "    for i in range(Y_hat.shape[1]):\n",
    "        if Y_hat[:, i] > 0.5:\n",
    "            Y_prediction[:, i] = 1\n",
    "        else:\n",
    "            Y_prediction[:, i] = 0\n",
    "\n",
    "    return Y_prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化参数\n",
    "对模型进行训练\n",
    "在训练过程中进行前向传播，损失函数计算，梯度下降\n",
    "找到最优解\n",
    "测试集预测\n",
    "模型评价\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练以及预测\n",
    "def Logisticmodel(X_train, Y_train, X_test, Y_test, num_iterations=1000, learning_rate=0.1):\n",
    "    # 初始化参数w，b\n",
    "    w, b = initialize_para(X_train.shape[0])\n",
    "    # 梯度下降找到最优参数\n",
    "    parameters, costs = optimize(\n",
    "        w, b, X_train, Y_train, num_iterations, learning_rate)\n",
    "\n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "\n",
    "    # 训练集测试集的预测结果\n",
    "    Y_prediction_train = predict(w, b, X_train)\n",
    "    Y_prediction_test = predict(w, b, X_test)\n",
    "    Y_prediction_test = Y_prediction_test.T\n",
    "\n",
    "    # 模型评价\n",
    "    accuracy_score_value = accuracy_score(Y_test, Y_prediction_test)\n",
    "    recall_score_value = recall_score(Y_test, Y_prediction_test)\n",
    "    precision_score_value = precision_score(Y_test, Y_prediction_test)\n",
    "    classification_report_value = classification_report(\n",
    "        Y_test, Y_prediction_test)\n",
    "\n",
    "    print(\"准确率:\", accuracy_score_value)\n",
    "    print(\"召回率:\", recall_score_value)\n",
    "    print(\"精确率:\", precision_score_value)\n",
    "    print(classification_report_value)\n",
    "\n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test,\n",
    "         \"Y_prediction_train\": Y_prediction_train,\n",
    "         \"w\": w,\n",
    "         \"b\": b,\n",
    "         \"learning_rate\": learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mingzi\\AppData\\Local\\Temp/ipykernel_11280/2452862511.py:23: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  pre_Y = pre_Y.astype(np.int)\n",
      "C:\\Users\\mingzi\\AppData\\Local\\Temp/ipykernel_11280/2408507428.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0/(1.0 + exp(-inx))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:0 Loss = 4.149707398394874, Acc = 0.6395604395604395\n",
      "Iteration:100 Loss = 7.261995447153545, Acc = 0.36923076923076925\n",
      "Iteration:200 Loss = 1.2224219136749777, Acc = 0.8923076923076922\n",
      "Iteration:300 Loss = 1.6699981769121266, Acc = 0.8549450549450549\n",
      "Iteration:400 Loss = 1.1892593350937857, Acc = 0.8967032967032967\n",
      "Iteration:500 Loss = 1.113328814240088, Acc = 0.9032967032967033\n",
      "Iteration:600 Loss = 1.113328814240088, Acc = 0.9032967032967033\n",
      "Iteration:700 Loss = 1.2434055249252671, Acc = 0.8901098901098901\n",
      "Iteration:800 Loss = 1.0627225054242007, Acc = 0.9076923076923077\n",
      "Iteration:900 Loss = 1.2398445885798706, Acc = 0.8923076923076922\n",
      "准确率: 0.9210526315789473\n",
      "召回率: 0.9090909090909091\n",
      "精确率: 0.9523809523809523\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91        48\n",
      "           1       0.95      0.91      0.93        66\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.92      0.92      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    X_train, X_test, y_train, y_test = loadTrainData()\n",
    "    Logisticmodel(X_train, y_train, X_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49cb93f377a7abe7414b7b0f21fb3017538004a126cf690fb524202736b7fb92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
